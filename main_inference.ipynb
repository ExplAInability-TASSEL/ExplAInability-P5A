{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_components.k_means import  CustomKMeans\n",
    "import numpy as np\n",
    "from model_components.CNN_model import Cplx_CustomCNN_1D\n",
    "from model_components.Attention_Layer import  AttentionLayer\n",
    "from model_components.classification import CustomClassifierModel\n",
    "import tensorflow as tf\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  segment_id  polygon_id  class_id  \\\n",
      "0           0      364025         3.0       1.0   \n",
      "1           1      367183         4.0       2.0   \n",
      "2           2      369134         4.0       2.0   \n",
      "3           3      369135         4.0       2.0   \n",
      "4           4      370405         4.0       2.0   \n",
      "\n",
      "                                              pixels  \\\n",
      "0  [[1133, 2933], [1133, 2934], [1133, 2935], [11...   \n",
      "1  [[1144, 2945], [1144, 2946], [1144, 2947], [11...   \n",
      "2  [[1149, 2941], [1149, 2942], [1149, 2943], [11...   \n",
      "3  [[1149, 2945], [1149, 2946], [1149, 2947], [11...   \n",
      "4  [[1153, 2941], [1153, 2942], [1153, 2943], [11...   \n",
      "\n",
      "                                    Perimeter Pixels  \\\n",
      "0  [[1133, 2933], [1134, 2933], [1135, 2933], [11...   \n",
      "1  [[1144, 2945], [1145, 2945], [1146, 2945], [11...   \n",
      "2  [[1149, 2941], [1150, 2941], [1151, 2941], [11...   \n",
      "3  [[1149, 2945], [1150, 2945], [1151, 2945], [11...   \n",
      "4  [[1153, 2941], [1154, 2941], [1155, 2941], [11...   \n",
      "\n",
      "                                        pixels_value  \n",
      "0  [[0.36342594, 0.41820988, 0.3294753, 0.5362654...  \n",
      "1  [[0.53780866, 0.5625, 0.48070988, 0.69521606, ...  \n",
      "2  [[0.58719134, 0.6041667, 0.50848764, 0.7075617...  \n",
      "3  [[0.43287036, 0.4675926, 0.37191358, 0.6180556...  \n",
      "4  [[0.5455247, 0.56558645, 0.48842594, 0.6643519...  \n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('/Users/thibaultgillard/Documents/EPF/git/Data/post_processed_data_train_100.csv')\n",
    "\n",
    "def extract_multiple_arrays(string_repr):\n",
    "    # Remove letters, parentheses, spaces, and unwanted sequences\n",
    "    string_repr = re.sub('[a-df-zA-DF-Z\\(\\)\\s]', '', string_repr)\n",
    "    string_repr = re.sub(r',=32', '', string_repr)\n",
    "\n",
    "    # Find all matches of arrays within the string\n",
    "    arrays = re.findall(r'\\[.*?\\]', string_repr)\n",
    "\n",
    "    # Convert each found array string into a NumPy array\n",
    "    #np_arrays = [np.array(re.findall(r'[+-]?\\d+(?:\\.\\d+)?', array), dtype=float) for array in arrays]\n",
    "    np_arrays = [np.array(re.findall(r'[+-]?\\d+(?:\\.\\d+)?(?:e[+-]?\\d+)?', array), dtype=float) for array in arrays]\n",
    "    return np_arrays\n",
    "\n",
    "df['pixels_value'] = df['pixels_value'].apply(extract_multiple_arrays)\n",
    "# pixels float to int\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "stacked_arrays = []\n",
    "\n",
    "# Stack the arrays for each cell\n",
    "for i, cell_pixels in enumerate(df['pixels_value']):\n",
    "    stacked_array = np.vstack(cell_pixels)\n",
    "    stacked_arrays.append(stacked_array)\n",
    "        \n",
    "n_clusters=2\n",
    "custom_kmeans = CustomKMeans(n_clusters=n_clusters)\n",
    "\n",
    "# Fit the model to the data and get the cluster centers\n",
    "clustered_data = []\n",
    "clustered_labels = []\n",
    "for i in range (len(stacked_arrays)):\n",
    "    custom_kmeans.fit(stacked_arrays[i])\n",
    "    clustered_data.append(custom_kmeans.get_cluster_centers())\n",
    "    clustered_labels.append(custom_kmeans.get_cluster_labels())\n",
    "    \n",
    "clusters = np.array(clustered_data)\n",
    "print(clusters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2324, 2, 73, 10)\n"
     ]
    }
   ],
   "source": [
    "print(clusters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Custom_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Custom_Model, self).__init__()\n",
    "        self.enc = Cplx_CustomCNN_1D()\n",
    "        self.attn = AttentionLayer()\n",
    "        self.classifier = CustomClassifierModel(num_classes=8, fc_units=64)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_list = tf.unstack(inputs, axis=1)\n",
    "        intermediate = [self.enc(input) for input in input_list]\n",
    "        intermediate = tf.stack(intermediate, axis=1)        \n",
    "        emb, alphas = self.attn(intermediate)\n",
    "        return self.classifier(emb), alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 01:01:32.303110: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-01-09 01:01:32.303168: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-01-09 01:01:32.303174: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-01-09 01:01:32.303242: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-09 01:01:32.303429: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       " array([[0.12246784, 0.12367103, 0.12714456, 0.12489398, 0.12778844,\n",
       "         0.12337242, 0.12485549, 0.12580626]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.49944344, 0.50055665]], dtype=float32)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = Custom_Model()\n",
    "input_shape = (2, 73, 10)\n",
    "\n",
    "# Create a dummy input tensor for model initialization\n",
    "dummy_input = tf.random.normal((1,) + input_shape)\n",
    "\n",
    "# Pass the dummy input through the model to initialize the layers\n",
    "model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights\n",
    "SAVE_PATH = 'saved_models/'\n",
    "\n",
    "model.load_weights(SAVE_PATH + 'model_weights_300_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom training loop to efficiently compute predictions and alphas\n",
    "batch_size = 32\n",
    "predictions = []\n",
    "all_alphas = []\n",
    "\n",
    "for i in range(0, len(clusters), batch_size):\n",
    "    batch_clusters = clusters[i:i+batch_size]\n",
    "    batch_predictions, batch_alphas = model(batch_clusters)\n",
    "    predictions.append(batch_predictions)\n",
    "    all_alphas.append(batch_alphas)\n",
    "\n",
    "# Concatenate predictions and alphas\n",
    "predictions = tf.concat(predictions, axis=0)\n",
    "all_alphas = tf.concat(all_alphas, axis=0)\n",
    "alphas = np.array(all_alphas)\n",
    "df_inferring = df.iloc[:, 1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>polygon_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Perimeter Pixels</th>\n",
       "      <th>pixels_cluster</th>\n",
       "      <th>alphas</th>\n",
       "      <th>heatmap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364025</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1133, 2933], [1133, 2934], [1133, 2935], [11...</td>\n",
       "      <td>[[1133, 2933], [1134, 2933], [1135, 2933], [11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.43, 0.58]</td>\n",
       "      <td>[0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367183</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1144, 2945], [1144, 2946], [1144, 2947], [11...</td>\n",
       "      <td>[[1144, 2945], [1145, 2945], [1146, 2945], [11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0.5, 0.51]</td>\n",
       "      <td>[0.51, 0.51, 0.51, 0.51, 0.51, 0.51, 0.51, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>369134</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1149, 2941], [1149, 2942], [1149, 2943], [11...</td>\n",
       "      <td>[[1149, 2941], [1150, 2941], [1151, 2941], [11...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0.57, 0.44]</td>\n",
       "      <td>[0.57, 0.57, 0.57, 0.57, 0.57, 0.57, 0.57, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>369135</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1149, 2945], [1149, 2946], [1149, 2947], [11...</td>\n",
       "      <td>[[1149, 2945], [1150, 2945], [1151, 2945], [11...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]</td>\n",
       "      <td>[0.75, 0.26]</td>\n",
       "      <td>[0.26, 0.26, 0.75, 0.75, 0.26, 0.26, 0.75, 0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370405</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[1153, 2941], [1153, 2942], [1153, 2943], [11...</td>\n",
       "      <td>[[1153, 2941], [1154, 2941], [1155, 2941], [11...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]</td>\n",
       "      <td>[0.55, 0.46]</td>\n",
       "      <td>[0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   segment_id  polygon_id  class_id  \\\n",
       "0      364025         3.0         1   \n",
       "1      367183         4.0         2   \n",
       "2      369134         4.0         2   \n",
       "3      369135         4.0         2   \n",
       "4      370405         4.0         2   \n",
       "\n",
       "                                              pixels  \\\n",
       "0  [[1133, 2933], [1133, 2934], [1133, 2935], [11...   \n",
       "1  [[1144, 2945], [1144, 2946], [1144, 2947], [11...   \n",
       "2  [[1149, 2941], [1149, 2942], [1149, 2943], [11...   \n",
       "3  [[1149, 2945], [1149, 2946], [1149, 2947], [11...   \n",
       "4  [[1153, 2941], [1153, 2942], [1153, 2943], [11...   \n",
       "\n",
       "                                    Perimeter Pixels  \\\n",
       "0  [[1133, 2933], [1134, 2933], [1135, 2933], [11...   \n",
       "1  [[1144, 2945], [1145, 2945], [1146, 2945], [11...   \n",
       "2  [[1149, 2941], [1150, 2941], [1151, 2941], [11...   \n",
       "3  [[1149, 2945], [1150, 2945], [1151, 2945], [11...   \n",
       "4  [[1153, 2941], [1154, 2941], [1155, 2941], [11...   \n",
       "\n",
       "                                      pixels_cluster        alphas  \\\n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]  [0.43, 0.58]   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, ...   [0.5, 0.51]   \n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]  [0.57, 0.44]   \n",
       "3   [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]  [0.75, 0.26]   \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]  [0.55, 0.46]   \n",
       "\n",
       "                                             heatmap  \n",
       "0  [0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.58, 0.5...  \n",
       "1  [0.51, 0.51, 0.51, 0.51, 0.51, 0.51, 0.51, 0.5...  \n",
       "2  [0.57, 0.57, 0.57, 0.57, 0.57, 0.57, 0.57, 0.5...  \n",
       "3  [0.26, 0.26, 0.75, 0.75, 0.26, 0.26, 0.75, 0.7...  \n",
       "4  [0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.5...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "df_inferring = df.iloc[:, 1:6]\n",
    "\n",
    "# Get the class with the highest probability\n",
    "df_inferring['class_id'] = np.argmax(predictions, axis=1) + 1\n",
    "df_inferring['class_id'] = df_inferring['class_id'].astype('int8')\n",
    "\n",
    "# Pixels' cluster\n",
    "df_inferring['pixels_cluster'] = clustered_labels\n",
    "\n",
    "\n",
    "df_inferring['alphas'] = alphas.tolist()\n",
    "\n",
    "# Function to round to the nearest hundredth\n",
    "def round_to_hundredth(lst):\n",
    "    return [math.ceil(num * 100) / 100 for num in lst]\n",
    "\n",
    "df_inferring['alphas'] = df_inferring['alphas'].apply(round_to_hundredth)\n",
    "\n",
    "\n",
    "# Function to replace the cluster labels with the corresponding alpha values, ideal to make a heatmap\n",
    "def replace_values(row):\n",
    "    return [row['alphas'][val] for val in row['pixels_cluster']]\n",
    "\n",
    "df_inferring['heatmap'] = df_inferring.apply(replace_values, axis=1)\n",
    "\n",
    "df_inferring.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
